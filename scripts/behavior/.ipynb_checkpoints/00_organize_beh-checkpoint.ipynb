{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54362280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01e247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_name_mapping(yaml_file, col_names, scale_metadata):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    # read yaml file with variable name mappings\n",
    "    with open(yaml_file, 'r') as f:\n",
    "        scale_name_json = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    item_dict = scale_name_json['items']\n",
    "\n",
    "    # some variables have aliases that we have to consider\n",
    "    items_w_alias = scale_metadata.loc[scale_metadata['Aliases'].notna()]\n",
    "\n",
    "    # dictionary with primary variable as key, comma-sep aliases as values\n",
    "    alias_dict = {item['ElementName']:item['Aliases'] for i,item in items_w_alias.iterrows()}\n",
    "\n",
    "    # map the descriptive variables to each of the alises \n",
    "    item_dict = add_aliases_to_item_dict(item_dict, alias_dict)\n",
    "\n",
    "    # map scale items to their descriptive names    \n",
    "    rename_dict  = match_items_to_newnames(col_names, item_dict)\n",
    "    return rename_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c794d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "#base_dir   = '/home/ubuntu/canbind-fsx'\n",
    "repo_dir   = '/home/ec2-user/SageMaker/suhas/canbind'\n",
    "clin_dir   = '/home/ec2-user/SageMaker/ebs/fsx/Clinical'\n",
    "yaml_dir   = Path(repo_dir, 'scripts/reference/behavior/scale_yamls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0e700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = [\n",
    "    'ATHF','BMI','BRIAN','CNSVS','DARS','DID','GAD7',\n",
    "    'IPAQ','MADRS','MINI','PSQI','QIDS','SDS','SHAPS','WHOQOL',\n",
    "    'BISBAS','BPI','CGI','DEMO','ECRR','HCL32','LEAPS',\n",
    "    'MEDHIS','NEOFFI','PSYHIS','QLESQ','SEXFX','SPAQ','YMRS'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ad102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sessions_dir = Path(base_dir, 'research/imaging/datasets/SRPBS/processed_data/pf-pipelines/qunex-nbridge/studies/CANBIND-20220818-mCcU5pi4/sessions')\n",
    "\n",
    "# read each behavioral scale\n",
    "scale_dict = {}\n",
    "for scale in scale_list: \n",
    "    data_list = []\n",
    "    for grp in ['Control', 'MDD']:\n",
    "        scale_dir  = Path(clin_dir, scale, grp)\n",
    "        csv_list   = list(Path(clin_dir, scale, grp).glob('*csv'))\n",
    "        if len(csv_list) == 1:\n",
    "            scale_df = pd.read_csv(csv_list[0])\n",
    "            data_list.append(scale_df)\n",
    "    if len(data_list) > 1:\n",
    "        scale_df = pd.concat(data_list)\n",
    "    else: \n",
    "        scale_df = data_list[0]\n",
    "    scale_dict[scale] = scale_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfb00804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- ATHF -------\n",
      "------- BMI -------\n",
      "------- BRIAN -------\n",
      "------- CNSVS -------\n",
      "------- DARS -------\n",
      "------- DID -------\n",
      "------- GAD7 -------\n",
      "------- IPAQ -------\n",
      "------- MADRS -------\n",
      "------- MINI -------\n",
      "------- PSQI -------\n",
      "------- QIDS -------\n",
      "------- SDS -------\n",
      "------- SHAPS -------\n",
      "------- WHOQOL -------\n",
      "------- BISBAS -------\n",
      "------- BPI -------\n",
      "------- CGI -------\n",
      "------- DEMO -------\n",
      "------- ECRR -------\n",
      "------- HCL32 -------\n",
      "------- LEAPS -------\n",
      "------- MEDHIS -------\n",
      "------- NEOFFI -------\n",
      "------- PSYHIS -------\n",
      "------- QLESQ -------\n",
      "------- SEXFX -------\n",
      "------- SPAQ -------\n",
      "------- YMRS -------\n"
     ]
    }
   ],
   "source": [
    "# rename columns using descriptive ids in reference yamls\n",
    "rename_scale_dict = {}\n",
    "for scale in scale_dict.keys():\n",
    "    print( f'------- {scale} -------')\n",
    "    scale_df  = scale_dict[scale]\n",
    "    \n",
    "    # read yaml\n",
    "    yaml_file = Path(yaml_dir, f'{scale.lower()}.yaml')    \n",
    "    with open(yaml_file, 'r') as f:\n",
    "        scale_name_json = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    # original id to descipritive id \n",
    "    item_dict = scale_name_json['items']\n",
    "    \n",
    "    # create a name dictionary for column replacement \n",
    "    newname_dict = {}\n",
    "    for item in scale_df.columns:\n",
    "        if item in item_dict.keys():\n",
    "            new_name = f'{scale}-{item}-{item_dict[item]}'\n",
    "            newname_dict[item] = new_name\n",
    "        else:\n",
    "            newname_dict[item] = item\n",
    "    \n",
    "    #save the renamed dataframe\n",
    "    rename_df = scale_df.copy()\n",
    "    rename_df.columns = rename_df.columns.map(newname_dict)\n",
    "    rename_scale_dict[scale] = rename_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6123789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- DARS -------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['SUBJLABEL', 'Group', 'EVENTNAME', 'Visitnum', 'DARS_B_1', 'DARS_B_2',\n",
       "       'DARS_B_3', 'DARS_B_4', 'DARS_B_5', 'DARS_B_6', 'DARS_B_7', 'DARS_B_8',\n",
       "       'DARS_B_9', 'DARS_Hobbies_Tot', 'DARS_D_10', 'DARS_D_11', 'DARS_D_12',\n",
       "       'DARS_D_13', 'DARS_D_14', 'DARS_D_15', 'DARS_Food_Tot', 'DARS_F_16',\n",
       "       'DARS_F_17', 'DARS_F_18', 'DARS_F_19', 'DARS_F_20', 'DARS_F_21',\n",
       "       'DARS_Social_Tot', 'DARS_H_22', 'DARS_H_23', 'DARS_H_24', 'DARS_H_25',\n",
       "       'DARS_H_26', 'DARS_Sense_Tot', 'DARS_Tot', 'comp_dars'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = 'DARS'\n",
    "\n",
    "keep_the_same = ['SUBJLABEL', 'Group', 'EVENTNAME', 'Visitnum']\n",
    "print( f'------- {scale} -------')\n",
    "scale_df  = scale_dict[scale]\n",
    "\n",
    "# read yaml\n",
    "yaml_file = Path(yaml_dir, f'{scale.lower()}.yaml')    \n",
    "with open(yaml_file, 'r') as f:\n",
    "    scale_name_json = yaml.load(f, Loader=yaml.FullLoader)\n",
    "# original id to descipritive id \n",
    "item_dict = scale_name_json['items']\n",
    "\n",
    "# create a name dictionary for column replacement \n",
    "newname_dict = {}\n",
    "for item in scale_df.columns:\n",
    "    if item in item_dict.keys():\n",
    "        new_name = f'{scale}-{item}-{item_dict[item]}'\n",
    "        newname_dict[item] = new_name\n",
    "    elif item in keep_the_same: \n",
    "        newname_dict[item] = item\n",
    "    else:\n",
    "        new_name = f'{scale}-{item}-{item}'\n",
    "\n",
    "#save the renamed dataframe\n",
    "rename_df = scale_df.copy()\n",
    "rename_df.columns = rename_df.columns.map(newname_dict)\n",
    "rename_scale_dict[scale] = rename_df\n",
    "\n",
    "scale_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83eb17c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATHF\n",
      "(323, 53)\n",
      "BMI\n",
      "(323, 57)\n",
      "BRIAN\n",
      "(323, 85)\n",
      "CNSVS\n",
      "(323, 180)\n",
      "DARS\n",
      "(323, 212)\n",
      "DID\n",
      "(323, 247)\n",
      "GAD7\n",
      "(323, 257)\n",
      "IPAQ\n",
      "(323, 268)\n",
      "MADRS\n",
      "(323, 280)\n",
      "MINI\n",
      "(323, 315)\n",
      "PSQI\n",
      "(323, 348)\n",
      "QIDS\n",
      "(323, 367)\n",
      "SDS\n",
      "(323, 374)\n",
      "SHAPS\n",
      "(323, 404)\n",
      "WHOQOL\n",
      "(323, 438)\n",
      "BISBAS\n",
      "(323, 466)\n",
      "BPI\n",
      "(323, 482)\n",
      "CGI\n",
      "(323, 484)\n",
      "ECRR\n",
      "(323, 537)\n",
      "HCL32\n",
      "(323, 574)\n",
      "LEAPS\n",
      "(323, 588)\n",
      "NEOFFI\n",
      "(323, 684)\n",
      "PSYHIS\n",
      "(323, 692)\n",
      "QLESQ\n",
      "(323, 711)\n",
      "SEXFX\n",
      "(323, 727)\n",
      "SPAQ\n",
      "(323, 877)\n",
      "YMRS\n",
      "(323, 891)\n"
     ]
    }
   ],
   "source": [
    "medhis_df = rename_scale_dict['MEDHIS']\n",
    "\n",
    "main_df = rename_scale_dict['DEMO']\n",
    "iter_scales =  [x for x in rename_scale_dict.keys() if x not in ['MEDHIS', 'DEMO']]\n",
    "for scale in iter_scales:\n",
    "    print(scale)\n",
    "    cur_df = rename_scale_dict[scale]\n",
    "    main_df = main_df.merge(cur_df, on=['SUBJLABEL', 'Group', 'EVENTNAME', 'Visitnum'], how='outer')\n",
    "    print(main_df.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d3b9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
